{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Workflow\n",
    "\n",
    "This example shows how to do a fully-automated run of the [introductory T20S tutorial workflow](https://guide.cryosparc.com/processing-data/get-started-with-cryosparc-introductory-tutorial) from in the CryoSPARC Guide. It includes the following steps:\n",
    "\n",
    "- Import Movies\n",
    "- Motion Correction\n",
    "- CTF Estimation\n",
    "- Curate Exposures\n",
    "- Blob Picker\n",
    "- Template Picker\n",
    "- Inspect Picks\n",
    "- Extract Particles\n",
    "- 2D Classification for Blob Picks\n",
    "- 2D Classification for Template Picks\n",
    "- Select 2D Classes\n",
    "- Ab-Initio Reconstruction\n",
    "- Homogeneous Refinement\n",
    "\n",
    "Use this example as a template for writing automated cryo-EM workflows that may\n",
    "be repeated with different datasets.\n",
    "\n",
    "## Import Movies\n",
    "\n",
    "First initialize a connection to CryoSPARC, find the target project and\n",
    "workspace where the workflow will run, and set a scheduler lane where jobs will\n",
    "be queued to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection succeeded to CryoSPARC command_core at http://cryoem0:40002\n",
      "Connection succeeded to CryoSPARC command_vis at http://cryoem0:40003\n",
      "Connection succeeded to CryoSPARC command_rtp at http://cryoem0:40005\n"
     ]
    }
   ],
   "source": [
    "from cryosparc.tools import CryoSPARC\n",
    "\n",
    "cs = CryoSPARC(host=\"cryoem0\", base_port=40000)\n",
    "assert cs.test_connection()\n",
    "\n",
    "project = cs.find_project(\"P251\")\n",
    "workspace = project.find_workspace(\"W10\")\n",
    "lane = \"cryoem3\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the movies with an Import Movies job. Note that you may use the `CryoSPARC.get_job_sections` method to inspect available job type keys to use with `Workspace.create_job`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sections = cs.get_job_sections()  # [{'contains': ['import_movies', 'import_micrographs', ...] ... }, ...]\n",
    "import_movies_job = workspace.create_job(\n",
    "    \"import_movies\",\n",
    "    params={\n",
    "        \"blob_paths\": \"/bulk5/data/EMPIAR/10025/data/empiar_10025_subset/*.tif\",\n",
    "        \"gainref_path\": \"/bulk5/data/EMPIAR/10025/data/empiar_10025_subset/norm-amibox05-0.mrc\",\n",
    "        \"psize_A\": 0.6575,\n",
    "        \"accel_kv\": 300,\n",
    "        \"cs_mm\": 2.7,\n",
    "        \"total_dose_e_per_A2\": 53,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may inspect any job's internal document to view available parameter keys, their standard titles, type and default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param key             | Title                             | Type    | Default\n",
      "================================================================================\n",
      "accel_kv              | Accelerating Voltage (kV)         | number  | None\n",
      "blob_paths            | Movies data path                  | path    | None\n",
      "compute_num_cpus      | Number of CPUs to parallelize     | number  | 4\n",
      "cs_mm                 | Spherical Aberration (mm)         | number  | None\n",
      "defect_path           | Defect file path                  | path    | None\n",
      "eer_num_fractions     | EER Number of Fractions           | number  | 40\n",
      "eer_upsamp_factor     | EER Upsampling Factor             | number  | 2\n",
      "gainref_flip_x        | Flip gain ref & defect file in X? | boolean | False\n",
      "gainref_flip_y        | Flip gain ref & defect file in Y? | boolean | False\n",
      "gainref_path          | Gain reference path               | path    | None\n",
      "gainref_rotate_num    | Rotate gain ref?                  | number  | 0\n",
      "negative_stain_data   | Negative Stain Data               | boolean | False\n",
      "output_constant_ctf   | Output Constant CTF               | boolean | False\n",
      "override_exp_group_id | Override Exposure Group ID        | number  | None\n",
      "phase_plate_data      | Phase Plate Data                  | boolean | False\n",
      "psize_A               | Raw pixel size (A)                | number  | None\n",
      "skip_header_check     | Skip Header Check                 | boolean | True\n",
      "total_dose_e_per_A2   | Total exposure dose (e/A^2)       | number  | None\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Param key':21s} | {'Title':33s} | {'Type':7s} | {'Default'}\")\n",
    "print(\"=\" * 80)\n",
    "for key, details in import_movies_job.doc[\"params_base\"].items():\n",
    "    print(f\"{key:21s} | {details['title']:33s} | {details['type']:7s} | {details['value']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make further parameter values with `Job.set_param` while the job is in 'building' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_movies_job.set_param(\"compute_num_cpus\", 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queue and run the job. Wait until it completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_movies_job.queue(lane)\n",
    "import_movies_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction and CTF Estimation\n",
    "Repeat with Patch Motion Correction and Patch CTF Estimation jobs. Use the `connections` parameter to connect the jobs to the Import Movies job and to each other.\n",
    "\n",
    "Both jobs may be queued at the same time. The CryoSPARC scheduler ensures both run to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_correction_job = workspace.create_job(\n",
    "    \"patch_motion_correction_multi\",\n",
    "    connections={\"movies\": (import_movies_job.uid, \"imported_movies\")},\n",
    "    params={\"compute_num_gpus\": 2},\n",
    ")\n",
    "ctf_estimation_job = workspace.create_job(\n",
    "    \"patch_ctf_estimation_multi\",\n",
    "    connections={\"exposures\": (motion_correction_job.uid, \"micrographs\")},\n",
    "    params={\"compute_num_gpus\": 2},\n",
    ")\n",
    "\n",
    "motion_correction_job.queue(lane)\n",
    "ctf_estimation_job.queue(lane)\n",
    "\n",
    "motion_correction_job.wait_for_done(), ctf_estimation_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Exposures\n",
    "\n",
    "Use half the micrographs to pick particles with the Blob picker. These will be\n",
    "used to generate more precise template-based picks on the full dataset. This\n",
    "requires running a Curate Exposures interactive job.\n",
    "\n",
    "```{note}\n",
    "Interactive jobs are special jobs that allow visual adjustment of data curation\n",
    "parameters from the CryoSPARC web interface. The following interactive jobs are\n",
    "used in this workflow:\n",
    "\n",
    "- Curate Exposures\n",
    "- Inspect Picks\n",
    "- Select 2D Classes\n",
    "\n",
    "When queued, interactive jobs soon enter status \"waiting\" (unlike regular jobs\n",
    "which get status \"running\"). This means they are ready for interaction from the\n",
    "CryoSPARC interface.\n",
    "\n",
    "After the job enters \"waiting\" status, either interact with the job from the\n",
    "CryoSPARC interface or use the `Job.interact` method to\n",
    "programmatically invoke the same interactive actions.\n",
    "\n",
    "Example interactive invocation for a Curate Exposures job:\n",
    "\n",
    "    data = job.interact(\"get_fields_and_thresholds\")\n",
    "\n",
    "This returns a curation data structure which may be mutated in Python and\n",
    "written back with the following:\n",
    "\n",
    "    job.interact(\"set_thresholds\", data)\n",
    "\n",
    "An interactive job has a shutdown function that may be invoked when interaction\n",
    "is complete. Example shutdown invocations for different interactive job types:\n",
    "\n",
    "| Job Type          | Shutdown Function                                                           |\n",
    "| ----------------- | --------------------------------------------------------------------------- |\n",
    "| Manual Picker     | `job.interact(\"begin_extract\", {\"box_size_pix\": ..., \"bin_size_pix\": ...})` |\n",
    "| Curate Exposures  | `job.interact(\"shutdown_interactive\")`                                      |\n",
    "| Inspect Picks     | `job.interact(\"shutdown_interactive\")`                                      |\n",
    "| Select 2D Classes | `job.interact(\"finish\")`                                                    |\n",
    "```\n",
    "\n",
    "Build and queue a Curate Exposures job and wait for \"waiting\" status.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waiting'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curate_exposures_job = workspace.create_job(\n",
    "    \"curate_exposures_v2\",\n",
    "    connections={\"exposures\": (ctf_estimation_job.uid, \"exposures\")},\n",
    ")\n",
    "\n",
    "curate_exposures_job.queue()\n",
    "curate_exposures_job.wait_for_status(\"waiting\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either curate exposures from the CryoSPARC interface or use `Job.interact` method to perform interactive job actions, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cryosparc.util import first\n",
    "\n",
    "data = curate_exposures_job.interact(\"get_fields_and_thresholds\")\n",
    "\n",
    "idx_field = first(field for field in data[\"fields\"] if field[\"name\"] == \"idx\")\n",
    "assert idx_field\n",
    "idx_field[\"thresholds\"] = [5, 14]\n",
    "idx_field[\"active\"] = True\n",
    "\n",
    "curate_exposures_job.interact(\"set_thresholds\", data)\n",
    "curate_exposures_job.interact(\"shutdown_interactive\")\n",
    "curate_exposures_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed explanation of the previous code block:\n",
    "1. Call `get_fields_and_thresholds` to get a dictionary with a `fields` key. The\n",
    "  value is a list of adjustable curation fields end thresholds. Each item has\n",
    "  this format:\n",
    "   ```py\n",
    "   {\n",
    "      'name': str,\n",
    "      'title': str\n",
    "      'short': str,\n",
    "      'active': bool,\n",
    "      'range': [number, number],\n",
    "      'thresholds': [number, number],\n",
    "   }\n",
    "   ```\n",
    "1. For each field to threshold (just the Index field in this case):\n",
    "   1. Modify the `thresholds` list to `[MIN, MAX]`, where\n",
    "      - `MIN` is a number greater than or equal to the first item in `range`\n",
    "      - `MAX` is a number less than or equal to the second item in `range`\n",
    "   1. Set `active` to `True` to enable the threshold\n",
    "1. Call `set_thresholds` with the modified dictionary\n",
    "1. Call `shutdown_interactive` to finish curating and wait until the job is\n",
    "   Completed.\n",
    "\n",
    "\n",
    "## Blob Picker\n",
    "\n",
    "The complated curation job will have 10 accepted and 10 rejected exposures. Provide the accepted ones as input to the Blob Picker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_picker_job = workspace.create_job(\n",
    "    \"blob_picker_gpu\",\n",
    "    connections={\"micrographs\": (curate_exposures_job.uid, \"exposures_accepted\")},\n",
    "    params={\"diameter\": 100, \"diameter_max\": 200},\n",
    ")\n",
    "blob_picker_job.queue(lane)\n",
    "blob_picker_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Picks\n",
    "\n",
    "Create an Inspect Picks job and interact with it similarly to Curate Exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_blob_picks_job = workspace.create_job(\n",
    "    \"inspect_picks_v2\",\n",
    "    connections={\n",
    "        \"micrographs\": (blob_picker_job.uid, \"micrographs\"),\n",
    "        \"particles\": (blob_picker_job.uid, \"particles\"),\n",
    "    },\n",
    ")\n",
    "inspect_blob_picks_job.queue()\n",
    "inspect_blob_picks_job.wait_for_status(\"waiting\")\n",
    "inspect_blob_picks_job.interact(\n",
    "    \"set_thresholds\",\n",
    "    {\"ncc_score_thresh\": 0.3, \"lpower_thresh_min\": 600, \"lpower_thresh_max\": 1000},\n",
    ")\n",
    "inspect_blob_picks_job.interact(\"shutdown_interactive\")\n",
    "inspect_blob_picks_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Classification\n",
    "\n",
    "Extract the selected particles and classify them with a 2D Classification job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_blob_picks_job = workspace.create_job(\n",
    "    \"extract_micrographs_cpu_parallel\",\n",
    "    connections={\n",
    "        \"micrographs\": (inspect_blob_picks_job.uid, \"micrographs\"),\n",
    "        \"particles\": (inspect_blob_picks_job.uid, \"particles\"),\n",
    "    },\n",
    "    params={\"box_size_pix\": 448},\n",
    ")\n",
    "\n",
    "classify_blob_picks_job = workspace.create_job(\n",
    "    \"class_2D\",\n",
    "    connections={\"particles\": (extract_blob_picks_job.uid, \"particles\")},\n",
    "    params={\"class2D_K\": 10},\n",
    ")\n",
    "\n",
    "extract_blob_picks_job.queue(lane)\n",
    "classify_blob_picks_job.queue(lane)\n",
    "\n",
    "extract_blob_picks_job.wait_for_done(), classify_blob_picks_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 2D Classes\n",
    "\n",
    "Create a Select 2D Classes job and either select templates from the CryoSPARC interface or interact with the job as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_blob_templates_job = workspace.create_job(\n",
    "    \"select_2D\",\n",
    "    connections={\n",
    "        \"particles\": (classify_blob_picks_job.uid, \"particles\"),\n",
    "        \"templates\": (classify_blob_picks_job.uid, \"class_averages\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "select_blob_templates_job.queue()\n",
    "select_blob_templates_job.wait_for_status(\"waiting\")\n",
    "\n",
    "# Auto-interact\n",
    "class_info = select_blob_templates_job.interact(\"get_class_info\")\n",
    "for c in class_info:\n",
    "    if 1.0 < c[\"res_A\"] < 19.0 and c[\"num_particles_total\"] > 900:\n",
    "        select_blob_templates_job.interact(\n",
    "            \"set_class_selected\",\n",
    "            {\n",
    "                \"class_idx\": c[\"class_idx\"],\n",
    "                \"selected\": True,\n",
    "            },\n",
    "        )\n",
    "select_blob_templates_job.interact(\"finish\")\n",
    "select_blob_templates_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Picker\n",
    "\n",
    "Create and run a Template Picker job with all micrographs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_picker_job = workspace.create_job(\n",
    "    \"template_picker_gpu\",\n",
    "    connections={\n",
    "        \"micrographs\": (ctf_estimation_job.uid, \"exposures\"),\n",
    "        \"templates\": (select_blob_templates_job.uid, \"templates_selected\"),\n",
    "    },\n",
    "    params={\"diameter\": 200},\n",
    ")\n",
    "template_picker_job.queue(lane)\n",
    "template_picker_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat all previous steps from Inspect Picks to Select 2D, using the template\n",
    "picks as input. Note that when queuing a series of connected jobs, only\n",
    "interactive jobs and the last job in the chain need to be waited on.\n",
    "\n",
    "\n",
    "For example, given the following job chain:\n",
    "\n",
    "    Inspect Picks -> Extract -> 2D Classification -> Select 2D Classes\n",
    "\n",
    "1. Queue all the jobs\n",
    "2. Wait for Inspect Picks to be interactive\n",
    "3. Invoke `shutdown_interactive` when finished interacting\n",
    "4. Wait for Select 2D Classes to be interactive (occurs after Extraction and 2D\n",
    "   Classification complete)\n",
    "5. Shutdown when finished interacting\n",
    "6. Wait for Select 2D to be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and connect jobs\n",
    "inspect_template_picks_job = workspace.create_job(\n",
    "    \"inspect_picks_v2\",\n",
    "    connections={\n",
    "        \"micrographs\": (template_picker_job.uid, \"micrographs\"),\n",
    "        \"particles\": (template_picker_job.uid, \"particles\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "extract_template_picks_job = workspace.create_job(\n",
    "    \"extract_micrographs_cpu_parallel\",\n",
    "    connections={\n",
    "        \"micrographs\": (inspect_template_picks_job.uid, \"micrographs\"),\n",
    "        \"particles\": (inspect_template_picks_job.uid, \"particles\"),\n",
    "    },\n",
    "    params={\"box_size_pix\": 448},\n",
    ")\n",
    "\n",
    "classify_template_picks_job = workspace.create_job(\n",
    "    \"class_2D\",\n",
    "    connections={\"particles\": (extract_template_picks_job.uid, \"particles\")},\n",
    "    params={\"class2D_K\": 50},\n",
    ")\n",
    "\n",
    "select_templates_job = workspace.create_job(\n",
    "    \"select_2D\",\n",
    "    connections={\n",
    "        \"particles\": (classify_template_picks_job.uid, \"particles\"),\n",
    "        \"templates\": (classify_template_picks_job.uid, \"class_averages\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Queue Jobs\n",
    "inspect_template_picks_job.queue()\n",
    "extract_template_picks_job.queue(lane)\n",
    "classify_template_picks_job.queue(lane)\n",
    "select_templates_job.queue()\n",
    "\n",
    "# Inspect template picks\n",
    "inspect_template_picks_job.wait_for_status(\"waiting\")\n",
    "inspect_template_picks_job.interact(\n",
    "    \"set_thresholds\",\n",
    "    {\"ncc_score_thresh\": 0.3, \"lpower_thresh_min\": 900.0, \"lpower_thresh_max\": 1800.0},\n",
    ")\n",
    "inspect_template_picks_job.interact(\"shutdown_interactive\")\n",
    "\n",
    "# Select 2D Classes\n",
    "select_templates_job.wait_for_status(\"waiting\")\n",
    "class_info = select_templates_job.interact(\"get_class_info\")\n",
    "for c in class_info:\n",
    "    if 1.0 < c[\"res_A\"] < 19.0 and c[\"num_particles_total\"] > 100:\n",
    "        select_templates_job.interact(\n",
    "            \"set_class_selected\",\n",
    "            {\n",
    "                \"class_idx\": c[\"class_idx\"],\n",
    "                \"selected\": True,\n",
    "            },\n",
    "        )\n",
    "select_templates_job.interact(\"finish\")\n",
    "select_templates_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction and Refinement\n",
    "\n",
    "Finally, queue and run Ab-Initio Reconstruction and Homogeneous Refinement jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abinit_job = workspace.create_job(\n",
    "    \"homo_abinit\",\n",
    "    connections={\"particles\": (select_templates_job.uid, \"particles_selected\")},\n",
    ")\n",
    "\n",
    "refine_job = workspace.create_job(\n",
    "    \"homo_refine_new\",\n",
    "    connections={\n",
    "        \"particles\": (abinit_job.uid, \"particles_all_classes\"),\n",
    "        \"volume\": (abinit_job.uid, \"volume_class_0\"),\n",
    "    },\n",
    "    params={\n",
    "        \"refine_symmetry\": \"D7\",\n",
    "        \"refine_defocus_refine\": True,\n",
    "        \"refine_ctf_global_refine\": True,\n",
    "    },\n",
    ")\n",
    "\n",
    "abinit_job.queue(lane)\n",
    "refine_job.queue(lane)\n",
    "\n",
    "abinit_job.wait_for_done(), refine_job.wait_for_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
