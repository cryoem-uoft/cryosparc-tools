{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Workflow\n",
    "\n",
    "This example shows how to do a fully-automated run of the [introductory T20S tutorial workflow](https://guide.cryosparc.com/processing-data/get-started-with-cryosparc-introductory-tutorial) from in the CryoSPARC Guide. It includes the following steps:\n",
    "\n",
    "- Import Movies\n",
    "- Motion Correction\n",
    "- CTF Estimation\n",
    "- Curate Exposures\n",
    "- Blob Picker\n",
    "- Template Picker\n",
    "- Inspect Picks\n",
    "- Extract Particles\n",
    "- 2D Classification for Blob Picks\n",
    "- 2D Classification for Template Picks\n",
    "- Select 2D Classes\n",
    "- Ab-Initio Reconstruction\n",
    "- Homogeneous Refinement\n",
    "\n",
    "Use this example as a template for writing automated cryo-EM workflows that may\n",
    "be repeated with different datasets.\n",
    "\n",
    "## Import Movies\n",
    "\n",
    "First initialize a connection to CryoSPARC, find the target project and\n",
    "workspace where the workflow will run, and set a scheduler lane where jobs will\n",
    "be queued to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection succeeded to CryoSPARC command_core at http://cryoem5:40002\n",
      "Connection succeeded to CryoSPARC command_vis at http://cryoem5:40003\n",
      "Connection succeeded to CryoSPARC command_rtp at http://cryoem5:40005\n"
     ]
    }
   ],
   "source": [
    "from cryosparc.tools import CryoSPARC\n",
    "\n",
    "cs = CryoSPARC(host=\"cryoem5\", base_port=40000)\n",
    "assert cs.test_connection()\n",
    "\n",
    "project = cs.find_project(\"P251\")\n",
    "workspace = project.find_workspace(\"W9\")\n",
    "lane = \"cryoem10\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the movies with an Import Movies job. Note that you may use the `CryoSPARC.get_job_sections` method to inspect available job type keys to use with `Workspace.create_job`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_sections = cs.get_job_sections()  # [{'contains': ['import_movies', 'import_micrographs', ...] ... }, ...]\n",
    "import_movies_job = workspace.create_job(\n",
    "    \"import_movies\",\n",
    "    params={\n",
    "        \"blob_paths\": \"/bulk5/data/EMPIAR/10025/data/empiar_10025_subset/*.tif\",\n",
    "        \"gainref_path\": \"/bulk5/data/EMPIAR/10025/data/empiar_10025_subset/norm-amibox05-0.mrc\",\n",
    "        \"psize_A\": 0.6575,\n",
    "        \"accel_kv\": 300,\n",
    "        \"cs_mm\": 2.7,\n",
    "        \"total_dose_e_per_A2\": 53,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may inspect any job's internal document to view available parameter keys, their standard titles, type and default values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Param key             | Title                             | Type    | Default\n",
      "================================================================================\n",
      "accel_kv              | Accelerating Voltage (kV)         | number  | None\n",
      "blob_paths            | Movies data path                  | path    | None\n",
      "compute_num_cpus      | Number of CPUs to parallelize     | number  | 4\n",
      "cs_mm                 | Spherical Aberration (mm)         | number  | None\n",
      "defect_path           | Defect file path                  | path    | None\n",
      "eer_num_fractions     | EER Number of Fractions           | number  | 40\n",
      "eer_upsamp_factor     | EER Upsampling Factor             | number  | 2\n",
      "gainref_flip_x        | Flip gain ref & defect file in X? | boolean | False\n",
      "gainref_flip_y        | Flip gain ref & defect file in Y? | boolean | False\n",
      "gainref_path          | Gain reference path               | path    | None\n",
      "gainref_rotate_num    | Rotate gain ref?                  | number  | 0\n",
      "negative_stain_data   | Negative Stain Data               | boolean | False\n",
      "output_constant_ctf   | Output Constant CTF               | boolean | False\n",
      "override_exp_group_id | Override Exposure Group ID        | number  | None\n",
      "phase_plate_data      | Phase Plate Data                  | boolean | False\n",
      "psize_A               | Raw pixel size (A)                | number  | None\n",
      "skip_header_check     | Skip Header Check                 | boolean | True\n",
      "total_dose_e_per_A2   | Total exposure dose (e/A^2)       | number  | None\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'Param key':21s} | {'Title':33s} | {'Type':7s} | {'Default'}\")\n",
    "print(\"=\" * 80)\n",
    "for key, details in import_movies_job.doc[\"params_base\"].items():\n",
    "    print(f\"{key:21s} | {details['title']:33s} | {details['type']:7s} | {details['value']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make further parameter values with `Job.set_param` while the job is in 'building' status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_movies_job.set_param(\"compute_num_cpus\", 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queue and run the job. Wait until it completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_movies_job.queue(lane)\n",
    "import_movies_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motion Correction and CTF Estimation\n",
    "Repeat with Patch Motion Correction and Patch CTF Estimation jobs. Use the `connections` parameter to connect the jobs to the Import Movies job and to each other.\n",
    "\n",
    "Both jobs may be queued at the same time. The CryoSPARC scheduler ensures both run to completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motion_correction_job = workspace.create_job(\n",
    "    \"patch_motion_correction_multi\",\n",
    "    connections={\"movies\": (import_movies_job.uid, \"imported_movies\")},\n",
    "    params={\"compute_num_gpus\": 2},\n",
    ")\n",
    "ctf_estimation_job = workspace.create_job(\n",
    "    \"patch_ctf_estimation_multi\",\n",
    "    connections={\"exposures\": (motion_correction_job.uid, \"micrographs\")},\n",
    "    params={\"compute_num_gpus\": 2},\n",
    ")\n",
    "\n",
    "motion_correction_job.queue(lane)\n",
    "ctf_estimation_job.queue(lane)\n",
    "\n",
    "motion_correction_job.wait_for_done(), ctf_estimation_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Curate Exposures\n",
    "\n",
    "Next, use half the micrographs to pick particles with the Blob picker. These will be used to generate more precise template-based picks on the full dataset.\n",
    "\n",
    "First build and queue a Curate Exposures job. Wait until it goes into \"Waiting\" status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'waiting'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curate_exposures_job = workspace.create_job(\n",
    "    \"curate_exposures_v2\", connections={\"exposures\": (ctf_estimation_job.uid, \"exposures\")}\n",
    ")\n",
    "\n",
    "curate_exposures_job.queue(lane)\n",
    "curate_exposures_job.wait_for_status(\"waiting\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either curate exposures from the CryoSPARC interface or use `Job.interact` method to perform interactive job actions, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cryosparc.util import first\n",
    "\n",
    "data = curate_exposures_job.interact(\"get_fields_and_thresholds\")\n",
    "\n",
    "idx_field = first(field for field in data[\"fields\"] if field[\"name\"] == \"idx\")\n",
    "assert idx_field\n",
    "idx_field[\"thresholds\"] = [5, 14]\n",
    "idx_field[\"active\"] = True\n",
    "\n",
    "curate_exposures_job.interact(\"set_thresholds\", data)\n",
    "curate_exposures_job.interact(\"shutdown_interactive\")\n",
    "curate_exposures_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detailed explanation of the previous code block:\n",
    "1. Call `get_fields_and_thresholds` to get a dictionary with a `fields` key. The\n",
    "  value is a list of adjustable curation fields end thresholds. Each item has\n",
    "  this format:\n",
    "   ```py\n",
    "   {\n",
    "      'name': str,\n",
    "      'title': str\n",
    "      'short': str,\n",
    "      'active': bool,\n",
    "      'range': [number, number],\n",
    "      'thresholds': [number, number],\n",
    "   }\n",
    "   ```\n",
    "1. For each field to threshold (just the Index field in this case):\n",
    "   1. Modify the `thresholds` list to `[MIN, MAX]`, where\n",
    "      - `MIN` is a number greater than or equal to the first item in `range`\n",
    "      - `MAX` is a number less than or equal to the second item in `range`\n",
    "   1. Set `active` to `True` to enable the threshold\n",
    "1. Call `set_thresholds` with the modified dictionary\n",
    "1. Call `shutdown_interactive` to finish curating and wait until the job is\n",
    "   Completed.\n",
    "\n",
    "\n",
    "## Blob Picker\n",
    "\n",
    "The complated curation job will have 10 accepted and 10 rejected exposures. Provide the accepted ones as input to the Blob Picker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_picker_job = workspace.create_job(\n",
    "    \"blob_picker_gpu\",\n",
    "    connections={\"micrographs\": (curate_exposures_job.uid, \"exposures_accepted\")},\n",
    "    params={\"diameter\": 100, \"diameter_max\": 200},\n",
    ")\n",
    "blob_picker_job.queue(lane)\n",
    "blob_picker_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Picks\n",
    "\n",
    "Create an Inspect Picks job and interact with it similarly to Curate Exposures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect_blob_picks_job = workspace.create_job(\n",
    "    \"inspect_picks_v2\",\n",
    "    connections={\n",
    "        \"micrographs\": (blob_picker_job.uid, \"micrographs\"),\n",
    "        \"particles\": (blob_picker_job.uid, \"particles\"),\n",
    "    },\n",
    ")\n",
    "inspect_blob_picks_job.queue(lane)\n",
    "inspect_blob_picks_job.wait_for_status(\"waiting\")\n",
    "inspect_blob_picks_job.interact(\n",
    "    \"set_thresholds\",\n",
    "    {\"ncc_score_thresh\": 0.3, \"lpower_thresh_min\": 600, \"lpower_thresh_max\": 1000},\n",
    ")\n",
    "inspect_blob_picks_job.interact(\"shutdown_interactive\")\n",
    "inspect_blob_picks_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D Classification\n",
    "\n",
    "Extract the selected particles and classify them with a 2D Classification job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_blob_picks_job = workspace.create_job(\n",
    "    \"extract_micrographs_cpu_parallel\",\n",
    "    connections={\n",
    "        \"micrographs\": (inspect_blob_picks_job.uid, \"micrographs\"),\n",
    "        \"particles\": (inspect_blob_picks_job.uid, \"particles\"),\n",
    "    },\n",
    "    params={\"box_size_pix\": 448},\n",
    ")\n",
    "\n",
    "classify_blob_picks_job = workspace.create_job(\n",
    "    \"class_2D\", connections={\"particles\": (extract_blob_picks_job.uid, \"particles\")}, params={\"class2D_K\": 10}\n",
    ")\n",
    "\n",
    "extract_blob_picks_job.queue(lane)\n",
    "classify_blob_picks_job.queue(lane)\n",
    "\n",
    "extract_blob_picks_job.wait_for_done(), classify_blob_picks_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select 2D Classes\n",
    "\n",
    "Create a Select 2D Classes job and either select templates from the CryoSPARC interface or interact with the job as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_blob_templates_job = workspace.create_job(\n",
    "    \"select_2D\",\n",
    "    connections={\n",
    "        \"particles\": (classify_blob_picks_job.uid, \"particles\"),\n",
    "        \"templates\": (classify_blob_picks_job.uid, \"class_averages\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "select_blob_templates_job.queue(lane)\n",
    "select_blob_templates_job.wait_for_status(\"waiting\")\n",
    "\n",
    "# Auto-interact\n",
    "class_info = select_blob_templates_job.interact(\"get_class_info\")\n",
    "for c in class_info:\n",
    "    if 1.0 < c[\"res_A\"] < 19.0 and c[\"num_particles_total\"] > 900:\n",
    "        select_blob_templates_job.interact(\n",
    "            \"set_class_selected\",\n",
    "            {\n",
    "                \"class_idx\": c[\"class_idx\"],\n",
    "                \"selected\": True,\n",
    "            },\n",
    "        )\n",
    "select_blob_templates_job.interact(\"finish\")\n",
    "select_blob_templates_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Template Picker\n",
    "\n",
    "Create and run a Template Picker job with all micrographs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template_picker_job = workspace.create_job(\n",
    "    \"template_picker_gpu\",\n",
    "    connections={\n",
    "        \"micrographs\": (ctf_estimation_job.uid, \"exposures\"),\n",
    "        \"templates\": (select_blob_templates_job.uid, \"templates_selected\"),\n",
    "    },\n",
    "    params={\"diameter\": 200},\n",
    ")\n",
    "template_picker_job.queue(lane)\n",
    "template_picker_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat all previous steps from Inspect Picks to Select 2D, using the template picks as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and connect jobs\n",
    "inspect_template_picks_job = workspace.create_job(\n",
    "    \"inspect_picks_v2\",\n",
    "    connections={\n",
    "        \"micrographs\": (template_picker_job.uid, \"micrographs\"),\n",
    "        \"particles\": (template_picker_job.uid, \"particles\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "extract_template_picks_job = workspace.create_job(\n",
    "    \"extract_micrographs_cpu_parallel\",\n",
    "    connections={\n",
    "        \"micrographs\": (inspect_template_picks_job.uid, \"micrographs\"),\n",
    "        \"particles\": (inspect_template_picks_job.uid, \"particles\"),\n",
    "    },\n",
    "    params={\"box_size_pix\": 448},\n",
    ")\n",
    "\n",
    "classify_template_picks_job = workspace.create_job(\n",
    "    \"class_2D\", connections={\"particles\": (extract_template_picks_job.uid, \"particles\")}, params={\"class2D_K\": 50}\n",
    ")\n",
    "\n",
    "select_templates_job = workspace.create_job(\n",
    "    \"select_2D\",\n",
    "    connections={\n",
    "        \"particles\": (classify_template_picks_job.uid, \"particles\"),\n",
    "        \"templates\": (classify_template_picks_job.uid, \"class_averages\"),\n",
    "    },\n",
    ")\n",
    "\n",
    "# Queue Jobs\n",
    "inspect_template_picks_job.queue(lane)\n",
    "extract_template_picks_job.queue(lane)\n",
    "classify_template_picks_job.queue(lane)\n",
    "select_templates_job.queue(lane)\n",
    "\n",
    "# Inspect template picks\n",
    "inspect_template_picks_job.wait_for_status(\"waiting\")\n",
    "inspect_template_picks_job.interact(\n",
    "    \"set_thresholds\",\n",
    "    {\"ncc_score_thresh\": 0.3, \"lpower_thresh_min\": 900.0, \"lpower_thresh_max\": 1800.0},\n",
    ")\n",
    "inspect_template_picks_job.interact(\"shutdown_interactive\")\n",
    "\n",
    "# Select 2D Classes\n",
    "select_templates_job.wait_for_status(\"waiting\")\n",
    "class_info = select_templates_job.interact(\"get_class_info\")\n",
    "for c in class_info:\n",
    "    if 1.0 < c[\"res_A\"] < 19.0 and c[\"num_particles_total\"] > 100:\n",
    "        select_templates_job.interact(\n",
    "            \"set_class_selected\",\n",
    "            {\n",
    "                \"class_idx\": c[\"class_idx\"],\n",
    "                \"selected\": True,\n",
    "            },\n",
    "        )\n",
    "select_templates_job.interact(\"finish\")\n",
    "select_templates_job.wait_for_done()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction and Refinement\n",
    "\n",
    "Finally, queue and run Ab-Initio Reconstruction and Homogeneous Refinement jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('completed', 'completed')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abinit_job = workspace.create_job(\n",
    "    \"homo_abinit\",\n",
    "    connections={\"particles\": (select_templates_job.uid, \"particles_selected\")},\n",
    ")\n",
    "\n",
    "refine_job = workspace.create_job(\n",
    "    \"homo_refine_new\",\n",
    "    connections={\"particles\": (abinit_job.uid, \"particles_all_classes\"), \"volume\": (abinit_job.uid, \"volume_class_0\")},\n",
    "    params={\"refine_symmetry\": \"D7\", \"refine_defocus_refine\": True, \"refine_ctf_global_refine\": True},\n",
    ")\n",
    "\n",
    "abinit_job.queue(lane)\n",
    "refine_job.queue(lane)\n",
    "\n",
    "abinit_job.wait_for_done(), refine_job.wait_for_done()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
